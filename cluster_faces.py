import json
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler # ğŸ‘ˆ [1.5ë‹¨ê³„] ì •ê·œí™”
from tqdm import tqdm
import warnings

# =====================================
# âš™ï¸ ì„¤ì •
# =====================================
# [ì…ë ¥] 1ë‹¨ê³„ì—ì„œ ìƒì„±ëœ íŠ¹ì§• íŒŒì¼
INPUT_FILE = "face_features.json"

# [ì¶œë ¥] í´ëŸ¬ìŠ¤í„°ë§(ê·¸ë£¹) ê²°ê³¼ê°€ ì €ì¥ë  íŒŒì¼
OUTPUT_FILE = "clustered_labels.json"

# [ì„¤ì •] ì–¼êµ´í˜•ì„ ëª‡ ê°œ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆŒ ê²ƒì¸ê°€
NUM_CLUSTERS = 5 

# Scikit-learnì˜ ê²½ê³  ë©”ì‹œì§€ ë„ê¸° (n_init ê´€ë ¨)
warnings.filterwarnings("ignore", category=UserWarning, module="sklearn")

# =====================================
# âœ… 1. ë°ì´í„° ë¡œë“œ
# =====================================
print(f"[1] íŠ¹ì§• ë°ì´í„° ë¡œë“œ ì¤‘... ({INPUT_FILE})")
try:
    with open(INPUT_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)
except FileNotFoundError:
    print(f"âŒ '{INPUT_FILE}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 1ë‹¨ê³„ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    exit()

if not data:
    print(f"âŒ '{INPUT_FILE}'ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 1ë‹¨ê³„ê°€ ì„±ê³µí–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    exit()

print(f" â€‚ â†’ ì´ {len(data)}ê°œì˜ íŠ¹ì§• ë°ì´í„° ë¡œë“œ ì™„ë£Œ.")

# K-Meansê°€ í•™ìŠµí•  'íŠ¹ì§•' ë¦¬ìŠ¤íŠ¸ì™€, ë‚˜ì¤‘ì— ë§¤í•‘í•  'ì´ë¯¸ì§€ ê²½ë¡œ' ë¦¬ìŠ¤íŠ¸ ë¶„ë¦¬
features_list = []
image_data_list = []

for item in data:
    features_list.append(item['features'])
    image_data_list.append({
        "image_path": item['image_path']
    })

# Numpy ë°°ì—´ë¡œ ë³€í™˜
X = np.array(features_list)

# =====================================
# âœ… 1.5ë‹¨ê³„: ë°ì´í„° ì •ê·œí™” (Standard Scaling)
# =====================================
print("[1.5] ë°ì´í„° ì •ê·œí™” ì§„í–‰ ì¤‘... (StandardScaler)")
# K-MeansëŠ” ê±°ë¦¬ ê¸°ë°˜ì´ë¯€ë¡œ, ëª¨ë“  íŠ¹ì§•ì˜ ë‹¨ìœ„ë¥¼ í†µì¼(ì •ê·œí™”)í•´ì•¼ í•¨
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
print(" â€‚ â†’ ì •ê·œí™” ì™„ë£Œ.")

# =====================================
# âœ… 2. K-Means í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰
# =====================================
print(f"[2] K-Means í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰ ì¤‘... (N={NUM_CLUSTERS}ê°œ ê·¸ë£¹)")

kmeans = KMeans(
    n_clusters=NUM_CLUSTERS, 
    random_state=42, # ê²°ê³¼ë¥¼ ì¼ì •í•˜ê²Œ ìœ ì§€í•˜ê¸° ìœ„í•œ ê°’
    n_init=10         # ì•ˆì •ì ì¸ ì¤‘ì‹¬ì ì„ ì°¾ê¸° ìœ„í•´ 10ë²ˆ ì‹œë„
)

# ì •ê·œí™”ëœ ë°ì´í„°ë¡œ í•™ìŠµ
kmeans.fit(X_scaled)

# ê° ë°ì´í„°(ì´ë¯¸ì§€)ê°€ ëª‡ ë²ˆ ê·¸ë£¹ì— ì†í•˜ëŠ”ì§€ ë¼ë²¨ì„ ê°€ì ¸ì˜´
labels = kmeans.labels_ # ì˜ˆ: [0, 2, 4, 1, 0, 0, 3, ...]

print(" â€‚ â†’ í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ.")

# =====================================
# âœ… 3. ê²°ê³¼ ì·¨í•© ë° ì €ì¥
# =====================================
print(f"[3] ìµœì¢… ë¼ë²¨ íŒŒì¼ ì €ì¥ ì¤‘... ({OUTPUT_FILE})")
output_data = []

for i in range(len(image_data_list)):
    item = image_data_list[i]
    item['cluster_id'] = int(labels[i]) # NumPy intë¥¼ Python intë¡œ ë³€í™˜
    output_data.append(item)

try:
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(output_data, f, indent=4, ensure_ascii=False)
except Exception as e:
    print(f"âŒ '{OUTPUT_FILE}' íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    exit()

print("\n--- [ğŸ‰ 2ë‹¨ê³„ ì™„ë£Œ] ---")
print(f"âœ… í´ëŸ¬ìŠ¤í„° ë¼ë²¨ íŒŒì¼: {OUTPUT_FILE}")
print(f" â€‚ â†’ ì´ {len(output_data)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ {NUM_CLUSTERS}ê°œ ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¥˜ ì™„ë£Œ.")
print("\nğŸ‘‰ ì´ì œ '3ë‹¨ê³„: ê²°ê³¼ ë¶„ì„'ì„ í†µí•´ ê° ê·¸ë£¹(0~4)ì´ ì–´ë–¤ ì–¼êµ´í˜•ì¸ì§€ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.")