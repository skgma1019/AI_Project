import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
import json
import os
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# =====================================
# âš™ï¸ ì„¤ì •
# =====================================
# [ì…ë ¥] 4ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ìµœì¢… í•™ìŠµ ë°ì´í„°ì…‹
DATASET_FILE = "final_training_data.json" 

# [ì¶œë ¥] í•™ìŠµëœ ëª¨ë¸ì„ ì €ì¥í•  íŒŒì¼
MODEL_SAVE_PATH = "face_shape_classifier.pth"

# í•˜ì´í¼ íŒŒë¼ë¯¸í„°
BATCH_SIZE = 32
LEARNING_RATE = 0.001
NUM_EPOCHS = 10 # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 10íšŒ ì„¤ì •, ì‹¤ì œëŠ” 30~50íšŒ í•„ìš”

# CPU/GPU ì„¤ì •
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"DEVICE: {DEVICE}")

# =====================================
# âœ… 1. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜
# =====================================

class FaceDataset(Dataset):
    def __init__(self, data_list, transform=None):
        self.data_list = data_list
        self.transform = transform
        # ë¼ë²¨ ì¸ì½”ë”© (ë¬¸ìì—´ ë¼ë²¨ì„ 0, 1, 2, 3, 4 ìˆ«ìë¡œ ë³€í™˜)
        self.label_map = {
            "ë‘¥ê·¼í˜•": 0, "ê¸´ íƒ€ì›í˜•": 1, "ê³„ë€í˜•": 2, 
            "ì—­ì‚¼ê°í˜•": 3, "ì‚¬ê°í˜•": 4
        }
    
    def __len__(self):
        return len(self.data_list)
    
    def __getitem__(self, idx):
        item = self.data_list[idx]
        img_path = item['image_path']
        label_name = item['face_shape']
        label_id = self.label_map[label_name]
        
        # [HOTFIX] í•œê¸€ ê²½ë¡œ ë¬¸ì œ í•´ê²°ëœ ì´ë¯¸ì§€ ë¡œë“œ ë°©ì‹ ì‚¬ìš©
        try:
            img_array = np.fromfile(img_path, np.uint8)
            image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # PyTorchëŠ” RGB ìˆœì„œ ì‚¬ìš©
        except:
            # ë¡œë“œ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ì´ë¯¸ì§€ ì‚¬ìš© (ë§¤ìš° ë“œë¬¼ì§€ë§Œ ì•ˆì „ì¥ì¹˜)
            # 0ìœ¼ë¡œ ì±„ì›Œì§„ ê²€ì€ìƒ‰ ì´ë¯¸ì§€ ë°˜í™˜
            image = np.zeros((224, 224, 3), dtype=np.uint8) 

        # PyTorchì˜ ìš”êµ¬ì‚¬í•­: ì´ë¯¸ì§€ í¬ê¸° 224x224ë¡œ ë³€í™˜ í›„ í…ì„œí™”
        if self.transform:
            # OpenCV ì´ë¯¸ì§€ë¥¼ PIL Imageë¡œ ë³€í™˜í•  í•„ìš” ì—†ì´ NumPy ë°°ì—´ì„ ì§ì ‘ ì²˜ë¦¬í•˜ë„ë¡ ì„¤ì •
            image = self.transform(image)
        
        return image, label_id

# =====================================
# âœ… 2. ë°ì´í„° ì¤€ë¹„ ë° ë¡œë” ìƒì„±
# =====================================

print(f"[1] ë°ì´í„° ë¡œë“œ ë° ë¶„ë¦¬ ì¤‘... ({DATASET_FILE})")
with open(DATASET_FILE, 'r', encoding='utf-8') as f:
    full_data = json.load(f)

# í•™ìŠµ(Train) 80%, ê²€ì¦(Validation) 20%ë¡œ ë¶„ë¦¬
train_data, val_data = train_test_split(
    full_data, test_size=0.2, random_state=42, 
    stratify=[item['face_shape'] for item in full_data] # ë¼ë²¨ ë¹„ìœ¨ ìœ ì§€
)

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì •ì˜
data_transforms = transforms.Compose([
    transforms.ToPILImage(), # NumPy ë°°ì—´ -> PIL Image ë³€í™˜ (Transforms í˜¸í™˜)
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

train_dataset = FaceDataset(train_data, transform=data_transforms)
val_dataset = FaceDataset(val_data, transform=data_transforms)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)

print(f" â€‚ â†’ í•™ìŠµ ë°ì´í„°: {len(train_dataset)}ê°œ, ê²€ì¦ ë°ì´í„°: {len(val_dataset)}ê°œ")

# =====================================
# âœ… 3. ëª¨ë¸ ì •ì˜ (ResNet18 ì „ì´ í•™ìŠµ)
# =====================================

print("[2] ResNet18 ëª¨ë¸ ë¡œë“œ ë° êµ¬ì¡° ë³€ê²½ ì¤‘...")
# ì‚¬ì „ í•™ìŠµëœ ResNet18 ëª¨ë¸ ë¡œë“œ
model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)

# ë§ˆì§€ë§‰ Fully Connected ë ˆì´ì–´ë§Œ ìš°ë¦¬ì˜ 5ê°€ì§€ ì¶œë ¥ í´ë˜ìŠ¤ì— ë§ê²Œ ë³€ê²½
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, len(FaceDataset(train_data).label_map))

model = model.to(DEVICE)

# ì†ì‹¤ í•¨ìˆ˜ ë° ìµœì í™” í•¨ìˆ˜ ì •ì˜
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

# =====================================
# âœ… 4. ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜
# =====================================

def train_model():
    best_acc = 0.0
    
    print(f"\n[3] ëª¨ë¸ í•™ìŠµ ì‹œì‘... (Epochs: {NUM_EPOCHS})")
    for epoch in range(NUM_EPOCHS):
        # --- Train Phase ---
        model.train()
        running_loss = 0.0
        
        # tqdmìœ¼ë¡œ í•™ìŠµ ì§„í–‰ë¥  í‘œì‹œ
        pbar_train = tqdm(train_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} (Train)", unit="batch")
        for inputs, labels in pbar_train:
            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)
            pbar_train.set_postfix(loss=loss.item())

        epoch_loss = running_loss / len(train_dataset)

        # --- Validation Phase ---
        model.eval()
        running_corrects = 0
        
        pbar_val = tqdm(val_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} (Valid)", unit="batch")
        with torch.no_grad():
            for inputs, labels in pbar_val:
                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)
                outputs = model(inputs)
                _, preds = torch.max(outputs, 1)
                running_corrects += torch.sum(preds == labels.data)

        epoch_acc = running_corrects.double() / len(val_dataset)
        
        # --- ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥ ---
        print(f"\n\nEpoch {epoch+1}/{NUM_EPOCHS} ì™„ë£Œ | Loss: {epoch_loss:.4f} | Val Acc: {epoch_acc:.4f}\n")

        # ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ ì €ì¥
        if epoch_acc > best_acc:
            best_acc = epoch_acc
            torch.save(model.state_dict(), MODEL_SAVE_PATH)
            print(f"*** ëª¨ë¸ ì €ì¥ ì™„ë£Œ (ì •í™•ë„: {best_acc:.4f}) ***")
    
    print("\n--- [ğŸ‰ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ] ---")
    print(f"ìµœê³  ê²€ì¦ ì •í™•ë„: {best_acc:.4f}")
    print(f"ìµœì¢… ëª¨ë¸ì€ '{MODEL_SAVE_PATH}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# =====================================
# âœ… 5. ì‹¤í–‰
# =====================================
if __name__ == '__main__':
    train_model()