import torch
import torch.nn as nn
from torchvision import transforms, models
import json
import os
import cv2
import numpy as np
from PIL import Image
import torch.nn.functional as F
import warnings

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings("ignore", category=UserWarning)

# =====================================
# âš™ï¸ ì„¤ì •
# =====================================
# [ì…ë ¥ 1] ëª¨ë¸ 1ì˜ 'ë‡Œ' (ì–¼êµ´í˜• ë¶„ë¥˜ê¸°)
MODEL_PATH = "face_shape_classifier.pth" 

# [ì…ë ¥ 2] ëª¨ë¸ 2ì˜ 'ë‡Œ' (ì¶”ì²œ í†µê³„)
STATS_FILE = "recommendation_stats.json"

# [ì…ë ¥ 3] ì‚¬ìš©ìê°€ ë¶„ì„í•  ì´ë¯¸ì§€
# !! ì—¬ê¸°ë¥¼ í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ì˜ ë¡œì»¬ ê²½ë¡œë¡œ ì§ì ‘ ìˆ˜ì •í•˜ì„¸ìš” !!
TEST_IMAGE_PATH = "test_imgs/gam.webp" # ğŸ‘ˆ (ì˜ˆì‹œ ê²½ë¡œ) ì´ ë¶€ë¶„ì„ ê¼­ ìˆ˜ì •í•˜ì„¸ìš”!

# [ì„¤ì •] ìƒìœ„ ëª‡ ê°œê¹Œì§€ ì¶”ì²œí• ì§€
TOP_K_RECOMMENDATIONS = 3

# CPU/GPU ì„¤ì •
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"DEVICE: {DEVICE}")

# =====================================
# âœ… 1ë‹¨ê³„: ëª¨ë¸ 1 (ì–¼êµ´í˜• ë¶„ë¥˜ê¸°) ë¡œë“œ
# =====================================
print(f"[1] ë¡œë”©: ì–¼êµ´í˜• ë¶„ë¥˜ê¸° ({MODEL_PATH})")
class_names = ["ë‘¥ê·¼í˜•", "ê¸´ íƒ€ì›í˜•", "ê³„ë€í˜•", "ì—­ì‚¼ê°í˜•", "ì‚¬ê°í˜•"]
NUM_CLASSES = len(class_names)

# ëª¨ë¸ ì•„í‚¤í…ì²˜ (í‹€) ìƒì„±
model = models.resnet18(weights=None)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, NUM_CLASSES)

# í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
try:
    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
except FileNotFoundError:
    print(f"âŒ ì˜¤ë¥˜: '{MODEL_PATH}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì½”ë©ì—ì„œ ë‹¤ìš´ë¡œë“œ í•„ìš”)")
    exit()

model = model.to(DEVICE)
model.eval() # ì¶”ë¡  ëª¨ë“œë¡œ ì„¤ì •

# =====================================
# âœ… 2ë‹¨ê³„: ëª¨ë¸ 2 (ì¶”ì²œ ì—”ì§„) ë¡œë“œ
# =====================================
print(f"[2] ë¡œë”©: ì¶”ì²œ ì—”ì§„ ({STATS_FILE})")
try:
    with open(STATS_FILE, 'r', encoding='utf-8') as f:
        stats_data = json.load(f)
except FileNotFoundError:
    print(f"âŒ ì˜¤ë¥˜: '{STATS_FILE}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (6ë‹¨ê³„ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ í•„ìš”)")
    exit()

# =====================================
# âœ… 3ë‹¨ê³„: ì…ë ¥ ì´ë¯¸ì§€ ì²˜ë¦¬
# =====================================
print(f"[3] ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘... ({TEST_IMAGE_PATH})")

# í•™ìŠµ ë•Œì™€ ë™ì¼í•œ ì „ì²˜ë¦¬
data_transforms = transforms.Compose([
    transforms.ToPILImage(), # NumPy -> PIL
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# í•œê¸€ ê²½ë¡œ ì´ë¯¸ì§€ ë¡œë“œ (ë¡œì»¬ PCìš©)
try:
    img_array = np.fromfile(TEST_IMAGE_PATH, np.uint8)
    image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
except Exception as e:
    print(f"âŒ ì˜¤ë¥˜: '{TEST_IMAGE_PATH}'ì—ì„œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# ì´ë¯¸ì§€ í…ì„œí™”
image_tensor = data_transforms(image).unsqueeze(0).to(DEVICE)

# =====================================
# âœ… 4ë‹¨ê³„: [ì‹¤í–‰] ì–¼êµ´í˜• ì˜ˆì¸¡ (ëª¨ë¸ 1)
# =====================================
print("[4] 1ë‹¨ê³„: ì–¼êµ´í˜• ë¶„ì„ ì‹¤í–‰...")
with torch.no_grad():
    outputs = model(image_tensor)
    probabilities = F.softmax(outputs, dim=1)[0]
    top_prob, top_idx = torch.max(probabilities, 0)
    
    predicted_face_shape = class_names[top_idx.item()]
    confidence = top_prob.item()

print(f" â¡ï¸ ë¶„ì„ ê²°ê³¼: {predicted_face_shape} (ì‹ ë¢°ë„: {confidence*100:.2f}%)")

# =====================================
# âœ… 5ë‹¨ê³„: [ì‹¤í–‰] í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œ (ëª¨ë¸ 2)
# =====================================
print("[5] 2ë‹¨ê³„: í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œ ì‹¤í–‰...")
if predicted_face_shape in stats_data:
    # ì˜ˆì¸¡ëœ ì–¼êµ´í˜•ì— ë§ëŠ” í—¤ì–´ìŠ¤íƒ€ì¼ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    recommendations = stats_data[predicted_face_shape]
    
    # ì„¤ì •í•œ TOP_K ë§Œí¼ ìƒìœ„ Nê°œ ì¶”ì¶œ
    top_k_list = recommendations[:TOP_K_RECOMMENDATIONS]
    
    # --- ìµœì¢… ê²°ê³¼ ì¶œë ¥ ---
    print("\n" + "="*40)
    print("      ğŸ‰ K-hairstyle AI ì¶”ì²œ ì‹œìŠ¤í…œ ğŸ‰")
    print("="*40)
    print(f"\n[ë¶„ì„ ê²°ê³¼]")
    print(f" â¡ï¸ ê³ ê°ë‹˜ì˜ ì–¼êµ´í˜•ì€ **'{predicted_face_shape}'**ì— ê°€ê¹ìŠµë‹ˆë‹¤.")
    print(f"    (ì‹ ë¢°ë„: {confidence*100:.2f}%)")
    
    print("\n[ì¶”ì²œ ìŠ¤íƒ€ì¼]")
    print(f" â¡ï¸ '{predicted_face_shape}' ì–¼êµ´í˜•ì„ ê°€ì§„ ë¶„ë“¤ì´")
    print(f"     ê°€ì¥ ë§ì´ ì„ íƒí•œ TOP {TOP_K_RECOMMENDATIONS} í—¤ì–´ìŠ¤íƒ€ì¼ì…ë‹ˆë‹¤.")
    print("-"*40)
    
    for i, item in enumerate(top_k_list, 1):
        print(f"   {i}ìˆœìœ„. {item['hairstyle']} (ì„ í˜¸ë„: {item['count']}ê±´)")
    
    print("="*40)

else:
    print(f"âŒ ì˜¤ë¥˜: ì¶”ì²œ ì—”ì§„ì— '{predicted_face_shape}' ì–¼êµ´í˜• ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")